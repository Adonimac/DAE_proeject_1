{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc4154be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "704683d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gorilla_tug_of_war.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load a dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgorilla_tug_of_war.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display first few rows\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gorilla_tug_of_war.csv'"
     ]
    }
   ],
   "source": [
    "# Load a dataset\n",
    "df = pd.read_csv('gorilla_tug_of_war.csv')\n",
    "\n",
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b7731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6af350",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba347d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['WHT', 'FRC', 'AGE'] :\n",
    "    sns.boxplot(data=df, x='SUS', y=i , color='crimson',\n",
    "        whiskerprops=dict(color='black'),\n",
    "        capprops=dict(color='black'),\n",
    "        medianprops=dict(color='black')\n",
    "               )\n",
    "    plt.title(f'{i} by Subspecies')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136bed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable:\n",
    "X = df.drop(columns=['HMNS'])\n",
    "y = df['HMNS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2906f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features into numerical and categorical columns\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd81c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157ca23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies of original train and test sets\n",
    "X_train_orig = X_train.copy()\n",
    "X_test_orig = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b2133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "def remove_outliers_iqr(df, numerical_cols):\n",
    "    df_filtered = df.copy()\n",
    "    for col in numerical_cols:\n",
    "        df_filtered[col] = df_filtered[col].astype(float)\n",
    "        Q1 = df_filtered[col].quantile(0.25)\n",
    "        Q3 = df_filtered[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_filtered = df_filtered[(df_filtered[col] >= lower_bound) & (df_filtered[col] <= upper_bound)]\n",
    "    return df_filtered\n",
    "\n",
    "X_train_filtered = remove_outliers_iqr(X_train, numerical_cols)\n",
    "y_train_filtered = y_train.loc[X_train_filtered.index]\n",
    "\n",
    "X_test_filtered = remove_outliers_iqr(X_test, numerical_cols)\n",
    "y_test_filtered = y_test.loc[X_test_filtered.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279bc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "X_train_cat_filtered = X_train_filtered[categorical_cols]\n",
    "X_train_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(X_train_cat_filtered),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols),\n",
    "    index=X_train_cat_filtered.index\n",
    ")\n",
    "\n",
    "X_test_cat_filtered = X_test_filtered[categorical_cols]\n",
    "X_test_encoded = pd.DataFrame(\n",
    "    encoder.transform(X_test_cat_filtered),\n",
    "    columns=encoder.get_feature_names_out(categorical_cols),\n",
    "    index=X_test_cat_filtered.index\n",
    ")\n",
    "\n",
    "X_train_final = pd.concat([X_train_filtered[numerical_cols], X_train_encoded], axis=1)\n",
    "X_test_final = pd.concat([X_test_filtered[numerical_cols], X_test_encoded], axis=1)\n",
    "\n",
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160eca28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([X_train_final,X_test_final])\n",
    "\n",
    "df_all['HMNS'] = pd.concat([y_train_filtered,y_test_filtered])\n",
    "\n",
    "\n",
    "\n",
    "df_all.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f6177",
   "metadata": {},
   "source": [
    "# Random Forest Feature Importance\n",
    "\n",
    "In our Random Forest regression model, we evaluate **feature importance** to understand which input variables have the most influence on the model's predictions.\n",
    "\n",
    "We use the **Mean Decrease in Impurity (MDI)** method, which is computed during the training process:\n",
    "\n",
    "- Each decision tree in the forest splits on features to reduce the **variance** (since we are doing regression).\n",
    "- For each feature, we track how much it reduces the total variance (impurity) across all trees.\n",
    "- The **importance score** for each feature is the **sum of these variance reductions**, averaged over all trees.\n",
    "\n",
    "This gives us a relative ranking of feature importance, helping us identify which features contribute most to accurate predictions.\n",
    "\n",
    "> Note: While MDI is efficient and built-in, it can be biased towards features with more unique values. If needed, we may use **permutation importance** as a more robust alternative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "df_encoded = df_all.copy()\n",
    "\n",
    "# Define X and y\n",
    "X = df_encoded.drop(columns=['HMNS'])\n",
    "y = df_encoded['HMNS']  # Replace with your actual target variable\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Aggregate SUS and GND importances\n",
    "sus_cols = [col for col in X.columns if col.startswith('SUS_')]\n",
    "gnd_cols = [col for col in X.columns if col.startswith('GND_')]\n",
    "\n",
    "importances_combined = importances.drop(sus_cols + gnd_cols).copy()\n",
    "importances_combined['SUS'] = importances[sus_cols].sum()\n",
    "importances_combined['GND'] = importances[gnd_cols].sum()\n",
    "\n",
    "# Sort for plotting\n",
    "importances_combined = importances_combined.sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "importances_combined.plot(kind='barh', color='magenta')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4aedc",
   "metadata": {},
   "source": [
    "# We recognize the significant weight of the 'WHT' feature. From this we can also look at how other features influence 'WHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36adc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define X and y\n",
    "X = df_encoded.drop(columns=['HMNS','WHT'])\n",
    "y = df_encoded['WHT']  # Replace with your actual target variable\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get feature importances\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\n",
    "# Aggregate SUS and GND importances\n",
    "sus_cols = [col for col in X.columns if col.startswith('SUS_')]\n",
    "gnd_cols = [col for col in X.columns if col.startswith('GND_')]\n",
    "\n",
    "importances_combined = importances.drop(sus_cols + gnd_cols).copy()\n",
    "importances_combined['SUS'] = importances[sus_cols].sum()\n",
    "importances_combined['GND'] = importances[gnd_cols].sum()\n",
    "\n",
    "# Sort for plotting\n",
    "importances_combined = importances_combined.sort_values(ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "importances_combined.plot(kind='barh', color='cyan')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16a3c6",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b1ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a copy to work on\n",
    "df_corr = df_encoded.copy()\n",
    "\n",
    "# Reconstruct SUS and GND from one-hot into single categorical codes\n",
    "df_corr['SUS'] = df_encoded[[col for col in df_encoded.columns if col.startswith('SUS_')]].idxmax(axis=1)\n",
    "df_corr['GND'] = df_encoded[[col for col in df_encoded.columns if col.startswith('GND_')]].idxmax(axis=1)\n",
    "\n",
    "# Convert from column names to category labels (e.g., 'SUS_Cross River' -> 'Cross River')\n",
    "df_corr['SUS'] = df_corr['SUS'].str.replace('SUS_', '')\n",
    "df_corr['GND'] = df_corr['GND'].str.replace('GND_', '')\n",
    "\n",
    "# Convert to numeric codes for correlation\n",
    "df_corr['SUS'] = df_corr['SUS'].astype('category').cat.codes\n",
    "df_corr['GND'] = df_corr['GND'].astype('category').cat.codes\n",
    "\n",
    "# Drop original one-hot columns and 'HMNS'\n",
    "df_corr = df_corr.drop(columns=[col for col in df_corr.columns if col.startswith(('SUS_', 'GND_', 'HMNS'))])\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df_corr.corr(method='pearson')\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, cmap='coolwarm', annot=True, fmt=\".2f\", square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix (with grouped SUS and GND)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b46a4e",
   "metadata": {},
   "source": [
    "### Relationship Between DSI, Age, and Weight\n",
    "\n",
    "We initially expected a correlation between **DSI** (Days Since Illness) and **weight**, under the assumption that recent illness would reduce appetite and lead to muscle atrophy. Similarly, we anticipated a strong correlation between **age** and **weight**, as infants naturally weigh less than adults.\n",
    "\n",
    "Additionally, we expected some correlation between **DSI** and **age**, assuming that older juveniles and early adults would be generally healthier, with fewer recent illnesses.\n",
    "\n",
    "However, the plot below show that these relationships are weak or nonexistent. As a result, both **DSI** and **age** can reasonably be dropped as predictive features in our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f24092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Set up the 3D plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(df_encoded['AGE'],  df_encoded['DSI'], df_encoded['WHT'], c=df_encoded['DSI'], cmap='inferno', s=50)\n",
    "\n",
    "# Axis labels\n",
    "ax.set_xlabel('AGE')\n",
    "ax.set_zlabel('WHT (Weight)')\n",
    "ax.set_ylabel('DSI (Days Since Illness)')\n",
    "\n",
    "plt.title('3D Plot: AGE vs WHT vs DSI')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a7c446",
   "metadata": {},
   "source": [
    "## Decoding for hues and styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19c579",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For SUS:find the column name with 1 in each row, then strip prefix\n",
    "sus_columns = [col for col in df_encoded.columns if col.startswith('SUS_')]\n",
    "df_encoded['SUS'] = df_encoded[sus_columns].idxmax(axis=1).str.replace('SUS_', '')\n",
    "\n",
    "# For GND: same logic\n",
    "gnd_columns = [col for col in df_encoded.columns if col.startswith('GND_')]\n",
    "df_encoded['GND'] = df_encoded[gnd_columns].idxmax(axis=1).str.replace('GND_', '')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac375a",
   "metadata": {},
   "source": [
    "# HMNS vs WHT colored by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e41ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define your color palette\n",
    "custom_palette2 = {\n",
    "    'Male': 'blue',\n",
    "    'Female': 'pink'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df_encoded, x='WHT', y='HMNS', hue='GND' , palette=custom_palette2 )\n",
    "\n",
    "plt.title('WHT vs HMNS colored by Gender')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c769c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "custom_palette = {\n",
    "    'Western Lowland': 'red',\n",
    "    'Mountain': 'green',\n",
    "    'Cross River': 'blue',\n",
    "    \"Grauer's\": 'black'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df_encoded, x='WHT', y='HMNS', hue='SUS' , style='GND'  ,palette=custom_palette)\n",
    "\n",
    "plt.title('WHT vs HMNS colored by Species')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4b829a",
   "metadata": {},
   "source": [
    "# HMNS vs FRC colored by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Define your color palette\n",
    "custom_palette2 = {\n",
    "    'Male': 'blue',\n",
    "    'Female': 'pink'\n",
    "}\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df, x='FRC', y='HMNS', hue='GND' , palette=custom_palette2 )\n",
    "\n",
    "plt.title('FRC vs HMNS colored by Gender')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df[df['WHT']<700], x='FRC', y='HMNS', hue='SUS' , style='GND'  ,palette=custom_palette)\n",
    "\n",
    "plt.title('AGE vs HMNS colored by DSI')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06567011",
   "metadata": {},
   "source": [
    "## Clear and visble Clusters between Male and Females are observed, now taking a look at the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_encoded[ (df_encoded['GND']=='Male' ) ] #males\n",
    "\n",
    "df_f = df_encoded[ (df_encoded['GND']=='Female') ] #females"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af43c8a",
   "metadata": {},
   "source": [
    "# Males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc18077",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df_m , x='WHT', y='HMNS', hue='SUS'   ,palette=custom_palette)\n",
    "\n",
    "plt.title('WHT vs HMNS colored by Species (Males)')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dda410",
   "metadata": {},
   "source": [
    "# Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cead6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "custom_palette = {\n",
    "    'Western Lowland': 'red',\n",
    "    'Mountain': 'green',\n",
    "    'Cross River': 'blue',\n",
    "    \"Grauer's\": 'black'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "sns.scatterplot(data=df_f , x='WHT', y='HMNS', hue='SUS'   ,palette=custom_palette)\n",
    "\n",
    "plt.title('WHT vs HMNS colored by Species (Females)')\n",
    "\n",
    "# Move legend to the right outside the plot\n",
    "plt.legend( bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99352a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Linear Regression</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation function for Linear Regression\n",
    "def evaluate_linear_regression(X_train, y_train, X_test, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48154e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_linear_regression(X_train_final, y_train_filtered, X_test_final, y_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23cdf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yeo-Johnson power transformation to reduce skewness\n",
    "skewed_feats = X_train_final[numerical_cols].apply(lambda x: x.skew()).sort_values(ascending=False)\n",
    "high_skew = skewed_feats[abs(skewed_feats) > 0.5].index.tolist()\n",
    "\n",
    "X_train_before_transform = X_train_final.copy()\n",
    "X_test_before_transform = X_test_final.copy()\n",
    "\n",
    "if len(high_skew) > 0:\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    X_train_final[high_skew] = pt.fit_transform(X_train_final[high_skew])\n",
    "    X_test_final[high_skew] = pt.transform(X_test_final[high_skew])\n",
    "\n",
    "    # palette = sns.color_palette(\"tab10\", 2) \n",
    "    num_cols = len(high_skew)\n",
    "    cols_per_row = 3\n",
    "    rows = (num_cols + cols_per_row - 1) // cols_per_row\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols_per_row, figsize=(6 * cols_per_row, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(high_skew):\n",
    "        sns.kdeplot(\n",
    "            data=X_train_before_transform, x=col, fill=True, color=palette[1], alpha=0.3, label='Before (Capped)', ax=axes[i]\n",
    "        )\n",
    "        sns.kdeplot(\n",
    "            data=X_train_final, x=col, fill=True, color=palette[0], alpha=0.7, label='After (Yeo-Johnson)', ax=axes[i]\n",
    "        )\n",
    "        axes[i].set_title(f'KDE for {col} (Before vs After)')\n",
    "        axes[i].legend()\n",
    "\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No highly skewed numerical features found to transform.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_linear_regression(X_train_final, y_train_filtered, X_test_final, y_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f985eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling \n",
    "scaler = MinMaxScaler()\n",
    "X_train_final[numerical_cols] = scaler.fit_transform(X_train_final[numerical_cols])\n",
    "X_test_final[numerical_cols] = scaler.transform(X_test_final[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcb924",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_linear_regression(X_train_final, y_train_filtered, X_test_final, y_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial features or interaction terms can capture nonlinear relationships\n",
    "poly_dict = {}\n",
    "X_train_num = X_train[numerical_cols].copy()\n",
    "\n",
    "for feature in numerical_cols:\n",
    "    for p in range(2, 5):\n",
    "        X_train_poly = X_train_num.copy()\n",
    "        new_col_name = f\"{feature}_pow_{p}\"\n",
    "        X_train_poly[new_col_name] = X_train_poly[feature] ** p\n",
    "\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(X_train_poly, y_train)\n",
    "        score = lr.score(X_train_poly, y_train) \n",
    "\n",
    "        poly_dict[score] = [feature, p]\n",
    "\n",
    "best_score = max(poly_dict.keys())\n",
    "best_feature, best_power = poly_dict[best_score]\n",
    "print(f\"Best polynomial feature: {best_feature}^{best_power} with R² score {best_score:.4f}\")\n",
    "\n",
    "poly_col_name = f\"{best_feature}_pow_{best_power}\"\n",
    "X_train[poly_col_name] = X_train[best_feature] ** best_power\n",
    "X_test[poly_col_name] = X_test[best_feature] ** best_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded086a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_linear_regression(X_train_final, y_train_filtered, X_test_final, y_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b2a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature interactions\n",
    "interaction_dict = {}\n",
    "columns_list = X_train_final.columns.tolist() \n",
    "\n",
    "for feat1, feat2 in combinations(columns_list, 2):\n",
    "    X_train_int = X_train_final.copy()\n",
    "    new_col_name = f\"{feat1}_x_{feat2}\"\n",
    "\n",
    "    X_train_int[new_col_name] = X_train_int[feat1] * X_train_int[feat2]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_int, y_train_filtered)\n",
    "\n",
    "    y_pred = model.predict(X_train_int)\n",
    "    r2 = r2_score(y_train_filtered, y_pred)\n",
    "\n",
    "    interaction_dict[r2] = (feat1, feat2)\n",
    "\n",
    "top_5_r2 = sorted(interaction_dict.keys(), reverse=True)[:5]\n",
    "\n",
    "for r2 in top_5_r2:\n",
    "    feat1, feat2 = interaction_dict[r2]\n",
    "    col_name = f\"{feat1}_x_{feat2}\"\n",
    "    \n",
    "    X_train_final[col_name] = X_train_final[feat1] * X_train_final[feat2]\n",
    "    X_test_final[col_name] = X_test_final[feat1] * X_test_final[feat2]\n",
    "\n",
    "    print(f\"Added interaction: {col_name} with R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5255d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_linear_regression(X_train_final, y_train_filtered, X_test_final, y_test_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dc802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection \n",
    "y_train_num = y_train_filtered.astype(float)\n",
    "y_test_num = y_test_filtered.astype(float)\n",
    "\n",
    "ridge_cv = RidgeCV(alphas=[0.01, 0.1, 1.0, 10.0, 100.0], cv=5)\n",
    "lasso_cv = LassoCV(alphas=[0.01, 0.1, 1.0, 10.0], cv=5, max_iter=10000)\n",
    "\n",
    "ridge_cv.fit(X_train_final, y_train_num)\n",
    "lasso_cv.fit(X_train_final, y_train_num)\n",
    "\n",
    "ridge_preds = ridge_cv.predict(X_test_final)\n",
    "lasso_preds = lasso_cv.predict(X_test_final)\n",
    "\n",
    "print(f\"Best Ridge alpha: {ridge_cv.alpha_}\")\n",
    "print(\"Ridge Regression R2:\", r2_score(y_test_num, ridge_preds))\n",
    "print(\"Ridge Regression MSE:\", mean_squared_error(y_test_num, ridge_preds))\n",
    "\n",
    "print(f\"\\nBest Lasso alpha: {lasso_cv.alpha_}\")\n",
    "print(\"Lasso Regression R2:\", r2_score(y_test_num, lasso_preds))\n",
    "print(\"Lasso Regression MSE:\", mean_squared_error(y_test_num, lasso_preds))\n",
    "\n",
    "ridge_coefs = pd.Series(ridge_cv.coef_, index=X_train_final.columns).sort_values(key=abs, ascending=False)\n",
    "lasso_coefs = pd.Series(lasso_cv.coef_, index=X_train_final.columns).sort_values(key=abs, ascending=False)\n",
    "\n",
    "selected_features = lasso_coefs[lasso_coefs != 0].index.tolist()\n",
    "print(f\"Selected features from Lasso: {selected_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train_final[selected_features]\n",
    "X_test_selected = X_test_final[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb67214",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_selected, y_train_num)\n",
    "\n",
    "y_pred = final_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluation metrics for regression\n",
    "mse = mean_squared_error(y_test_num, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_num, y_pred)\n",
    "r2 = r2_score(y_test_num, y_pred)\n",
    "\n",
    "print(f\"Final Model - MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187ff95",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bcefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10, 20, 50, 100, 200],\n",
    "    'fit_intercept': [True, False],\n",
    "    'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'saga'],\n",
    "    'tol': [1e-4, 1e-3, 1e-2],\n",
    "    'max_iter': [1000, 3000, 5000, 10000]\n",
    "}\n",
    "\n",
    "\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ridge,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_selected, y_train_num)\n",
    "\n",
    "print(\"Best negative MSE: {:.4f}\".format(grid_search.best_score_))\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "mse = mean_squared_error(y_test_num, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test_num, y_pred)\n",
    "r2 = r2_score(y_test_num, y_pred)\n",
    "\n",
    "print(f\"Test Set - MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | R²: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdc61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
